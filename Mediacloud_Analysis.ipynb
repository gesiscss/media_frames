{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ncov-or-cov-19-or-covid-o-all-story-urls-20200628121924.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only rows where files exist\n",
    "\n",
    "files = []\n",
    "for file in os.listdir('Mediacloud/'):\n",
    "    files.append(file[:-4])\n",
    "\n",
    "df = df[df['stories_id'].isin(files)]\n",
    "df['Text'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading files and adding text to the dataframe\n",
    "\n",
    "for file in os.listdir('Mediacloud/'):\n",
    "    with open('Mediacloud/' + file, 'r') as text:\n",
    "        data = text.read().replace('\\n', '')\n",
    "        df.loc[df['stories_id'] == int(file[:-4]), 'Text'] = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating text length and briefly describing it\n",
    "\n",
    "df['text_len'] = df['Text'].apply(lambda x: len(str(x).split()) if x else np.nan)\n",
    "print(df['text_len'].describe())\n",
    "df.hist(column='text_len', bins=15, grid=False, figsize=(12,8), color='#86bf91', zorder=2, rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting those rows where more than 100 words are present in the text\n",
    "\n",
    "df = df[df['text_len'] > 100].reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the text and returning tokens\n",
    "\n",
    "def text_processing(input_str):\n",
    "    input_lower = input_str.lower()\n",
    "    input_punctutation = input_lower.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).replace(' '*4, ' ').replace(' '*3, ' ').replace(' '*2, ' ').strip()\n",
    "    input_tokens = nltk.word_tokenize(input_punctutation)\n",
    "    input_stopwords = [i for i in input_tokens if not i in stop_words]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    input_lemmatized = [lemmatizer.lemmatize(word) for word in input_stopwords]\n",
    "    return (input_lemmatized)\n",
    "    \n",
    "df['tokens'] = df['Text'].apply(lambda x: text_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the frequency of words and return freq of corona-related terms\n",
    "\n",
    "def wordListToFreqDict(wordlist, terms):\n",
    "    wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "    res = dict(list(zip(wordlist,wordfreq)))\n",
    "    return [(term, res[term]) for term in terms if term in res.keys()]\n",
    "\n",
    "with open('corona_terms.txt', 'r') as corona_terms:\n",
    "    terms = corona_terms.read().replace('\\n', ' ').split(' ')\n",
    "\n",
    "df['corona_terms'] = df['tokens'].apply(lambda x: wordListToFreqDict(x, terms))\n",
    "df['corona_freq'] = df['corona_terms'].apply(lambda x: sum([item[1] for item in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corona_freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona = df[df['corona_freq'] >3]\n",
    "df_corona.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'][3499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
