{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import ast \n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import ward, dendrogram, fcluster, single, complete\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGRAMS = True #a parameter that specifies if unigrams (false) or bigrams (true) are used\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "cv = CountVectorizer(analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None)\n",
    "\n",
    "def make_bigrams(bigram_mod, texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def read_and_vectorize(path, cv, bigrams):\n",
    "    df = pd.read_csv(path)\n",
    "    df['tokens'] = df['tokens'].apply(ast.literal_eval) #transforming string of tokens to list\n",
    "    if bigrams == True: #specify if bigrams or unigrams are used for future clustering\n",
    "        bigram = gensim.models.Phrases(df['tokens'], min_count=3, threshold=50) # higher threshold fewer phrases.\n",
    "        bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "        df['bigrams'] = make_bigrams(bigram_mod, df['tokens'])\n",
    "        print('Bigrams are created.')\n",
    "        data = cv.fit_transform(df['bigrams'])\n",
    "    else:\n",
    "        data = cv.fit_transform(df['tokens'])\n",
    "    terms = cv.get_feature_names()\n",
    "    print(f'Len of terms: {len(terms)}')\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf_matrix = tfidf_transformer.fit_transform(data)\n",
    "    print(f'Tfidf matrix is generated of shape {tfidf_matrix.shape}')\n",
    "    return df, tfidf_matrix, terms\n",
    "\n",
    "df_feb, tfidf_matrix_feb, terms_feb = read_and_vectorize('preprocessed_results/mediacloud_parsed_corona_df_feb_sample.csv', cv, BIGRAMS)\n",
    "df_may, tfidf_matrix_may, terms_may = read_and_vectorize('preprocessed_results/mediacloud_parsed_corona_df_may_sample.csv', cv, BIGRAMS)\n",
    "df_sep, tfidf_matrix_sep, terms_sep = read_and_vectorize('preprocessed_results/mediacloud_parsed_corona_df_sep_sample.csv', cv, BIGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_best_kmeans_model(path):\n",
    "    models_df = pd.read_csv(path)\n",
    "    best_model = models_df.iloc[models_df['Coherence'].idxmax()]\n",
    "    return best_model, models_df\n",
    "\n",
    "best_model_feb, models_df_feb = read_best_kmeans_model('preprocessed_results/models_df_feb.csv')\n",
    "best_model_may, models_df_may = read_best_kmeans_model('preprocessed_results/models_df_may.csv')\n",
    "best_model_sep, models_df_sep = read_best_kmeans_model('preprocessed_results/models_df_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tfidf_matrix):\n",
    "    transformed_tokens = np.empty((tfidf_matrix.shape[0], 0)).tolist()\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        transformed_tokens[i] = tfidf_matrix[i].toarray()[0]\n",
    "    print(f'Matrix is tranformed into array of len {len(transformed_tokens)}')\n",
    "    return np.array(transformed_tokens)\n",
    "\n",
    "def plot_linkage(linkage_matrix, clusters):\n",
    "    fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
    "    ax = dendrogram(linkage_matrix, orientation=\"right\", labels=clusters)\n",
    "\n",
    "    plt.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def hierarchical_clustering(best_model, tfidf_matrix, cluster):\n",
    "    random_state = 20\n",
    "    transformed_tokens = transform(tfidf_matrix)\n",
    "    \n",
    "    model = KMeans(n_clusters=best_model['Num_Topics'], init='k-means++', max_iter=100, n_init=1, random_state = random_state)\n",
    "    clusters = model.fit_predict(transformed_tokens)\n",
    "    selected_features = [transformed_tokens[i] for i in range(len(transformed_tokens)) if clusters[i]==cluster]\n",
    "    svd = TruncatedSVD(n_components=100, random_state=random_state)\n",
    "    features = svd.fit_transform(selected_features)\n",
    "    print(features.shape)\n",
    "    linkage_matrix = ward(features)\n",
    "    plot_linkage(linkage_matrix, clusters)\n",
    "    return features, transformed_tokens, linkage_matrix, clusters\n",
    "\n",
    "features_hierarchical_feb, transformed_tokens_feb, linkage_matrix_feb, clusters_feb = hierarchical_clustering(best_model_feb, tfidf_matrix_feb, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_clustering(n_clusters, features, df, cluster, best_model, transformed_tokens, clusters):\n",
    "    random_state=20\n",
    "    model_hierarchical = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    model_hierarchical.fit_predict(features)\n",
    "    \n",
    "#     model = KMeans(n_clusters=best_model['Num_Topics'], init='k-means++', max_iter=100, n_init=1, random_state = random_state)\n",
    "#     clusters = model.fit_predict(transformed_tokens)\n",
    "    df = df[clusters==cluster]\n",
    "    \n",
    "    for label in range(model_hierarchical.n_clusters_):\n",
    "        print(label)\n",
    "        display(df[model_hierarchical.labels_==label]['title'])\n",
    "        \n",
    "agglomerative_clustering(23, features_hierarchical_feb, df_feb, 6, best_model_feb, transformed_tokens_feb, clusters_feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_k(distance_matrix, linkage_matrix, max_k=20):\n",
    "    scores = []\n",
    "    for i in range(2, max_k+1):\n",
    "        clusters = fcluster(linkage_matrix, i, criterion='maxclust')\n",
    "        score = silhouette_score(distance_matrix, clusters, metric='precomputed')\n",
    "        print(\"Silhouette score with {} clusters:\".format(i), score)\n",
    "        scores.append(score)\n",
    "    plt.title(\"Silhouette score vs. number of clusters\")\n",
    "    plt.xlabel(\"# of clusters\")\n",
    "    plt.ylabel(\"Score (higher is better)\")\n",
    "    plt.plot(np.arange(2, max_k+1), scores)\n",
    "    plt.show()\n",
    "    return scores\n",
    "\n",
    "def elbow_method(tfidf_matrix, linkage_matrix):\n",
    "    dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "    dist = dist - dist.min() \n",
    "    silhouette_k(dist, linkage_matrix, max_k=30)\n",
    "    \n",
    "elbow_method(tfidf_matrix_feb[clusters_feb==6], linkage_matrix_feb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hierarchical_may, transformed_tokens_may, linkage_matrix_may, clusters_may = hierarchical_clustering(best_model_may, tfidf_matrix_may, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_clustering(6, features_hierarchical_may, df_may, 2, best_model_may, transformed_tokens_may, clusters_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_method(tfidf_matrix_may[clusters_may==2], linkage_matrix_may)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hierarchical_sep, transformed_tokens_sep, linkage_matrix_sep, clusters_sep = hierarchical_clustering(best_model_sep, tfidf_matrix_sep, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_clustering(2, features_hierarchical_sep, df_sep, 10, best_model_sep, transformed_tokens_sep, clusters_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
